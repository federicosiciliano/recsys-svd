{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nRCG0Q8347G"
   },
   "source": [
    "# Preparation stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c81IM9YmWpCp"
   },
   "source": [
    "## Connect to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 1076,
     "status": "ok",
     "timestamp": 1728035948320,
     "user": {
      "displayName": "maria diana calugaru",
      "userId": "15328572193410378426"
     },
     "user_tz": -120
    },
    "id": "EoEPCwJGdpz_"
   },
   "outputs": [],
   "source": [
    "connect_to_drive = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31670,
     "status": "ok",
     "timestamp": 1728035983317,
     "user": {
      "displayName": "maria diana calugaru",
      "userId": "15328572193410378426"
     },
     "user_tz": -120
    },
    "id": "QgLWUVMAWpCq",
    "outputId": "5f5dc75b-874e-4408-ac48-820bf45f61bc"
   },
   "outputs": [],
   "source": [
    "#Run command and authorize by popup --> other window\n",
    "if connect_to_drive:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzMilQQcEL-w"
   },
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17107,
     "status": "ok",
     "timestamp": 1728036005252,
     "user": {
      "displayName": "maria diana calugaru",
      "userId": "15328572193410378426"
     },
     "user_tz": -120
    },
    "id": "w9_OVsonPEi1",
    "outputId": "c55c10c6-e528-4c4c-d546-5e13ba7bd75c"
   },
   "outputs": [],
   "source": [
    "if connect_to_drive:\n",
    "    #Install FS code\n",
    "    #!pip install  --upgrade --no-deps --force-reinstall git+https://github.com/federicosiciliano/easy_lightning.git@fedsic\n",
    "    !pip install  --upgrade --no-deps --force-reinstall git+https://github.com/PokeResearchLab/easy_lightning.git\n",
    "\n",
    "    !pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llsyZg59yyiX"
   },
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4813,
     "status": "ok",
     "timestamp": 1728036017022,
     "user": {
      "displayName": "maria diana calugaru",
      "userId": "15328572193410378426"
     },
     "user_tz": -120
    },
    "id": "U0GsBSD6yz9y"
   },
   "outputs": [],
   "source": [
    "#Put all imports here\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from copy import deepcopy\n",
    "#import pickle\n",
    "import os\n",
    "import sys\n",
    "#import cv2\n",
    "import torch\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnSShc_Yy4lr"
   },
   "source": [
    "## Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 523,
     "status": "ok",
     "timestamp": 1728036032115,
     "user": {
      "displayName": "maria diana calugaru",
      "userId": "15328572193410378426"
     },
     "user_tz": -120
    },
    "id": "WRYc5NEeyjQ8"
   },
   "outputs": [],
   "source": [
    "#every path should start from the project folder:\n",
    "project_folder = \"../\"\n",
    "if connect_to_drive:\n",
    "    project_folder = \"/content/gdrive/Shareddrives/<SharedDriveName>\" #Name of SharedDrive folder\n",
    "    #project_folder = \"/content/gdrive/MyDrive/<MyDriveName>\" #Name of MyDrive folder\n",
    "\n",
    "#Config folder should contain hyperparameters configurations\n",
    "cfg_folder = os.path.join(project_folder,\"cfg\")\n",
    "\n",
    "#Data folder should contain raw and preprocessed data\n",
    "data_folder = os.path.join(project_folder,\"data\")\n",
    "raw_data_folder = os.path.join(data_folder,\"raw\")\n",
    "processed_data_folder = os.path.join(data_folder,\"processed\")\n",
    "\n",
    "#Source folder should contain all the (essential) source code\n",
    "source_folder = os.path.join(project_folder,\"src\")\n",
    "\n",
    "#The out folder should contain all outputs: models, results, plots, etc.\n",
    "out_folder = os.path.join(project_folder,\"out\")\n",
    "img_folder = os.path.join(out_folder,\"img\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4fhGkp14CSb"
   },
   "source": [
    "## Import own code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "executionInfo": {
     "elapsed": 619,
     "status": "error",
     "timestamp": 1728036036278,
     "user": {
      "displayName": "maria diana calugaru",
      "userId": "15328572193410378426"
     },
     "user_tz": -120
    },
    "id": "FEky-72g943f",
    "outputId": "76e8dad9-38c3-401d-b688-0dbcc53ab56b"
   },
   "outputs": [],
   "source": [
    "#To import from src:\n",
    "\n",
    "#attach the source folder to the start of sys.path\n",
    "sys.path.insert(0, project_folder)\n",
    "\n",
    "#import from src directory\n",
    "from src.module import *\n",
    "from src.pruning import *\n",
    "\n",
    "import easy_exp, easy_rec, easy_torch #easy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIslF_wh31z2"
   },
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSozb3hnPEi4"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9gCiPA9dp0H"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "1oW5REUm4GC8"
   },
   "outputs": [],
   "source": [
    "cfg = easy_exp.cfg.load_configuration(\"config_rec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "De8GmtGYPEi4"
   },
   "outputs": [],
   "source": [
    "cfg[\"data_params\"][\"data_folder\"] = raw_data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "mmEpjTWdPEi5",
    "outputId": "0f937531-5fda-4c34-ab77-cd324d262972"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings data already exists. Skip pre-processing\n",
      "Filtering by minimum number of users per item: 5\n",
      "Filtering by minimum number of items per user: 5\n",
      "Densifying index\n",
      "Splitting: leave_n_out\n"
     ]
    }
   ],
   "source": [
    "#cfg[\"data_params\"][\"test_sizes\"] = [cfg[\"data_params.dataset_params.out_seq_len.val\"],cfg[\"data_params.dataset_params.out_seq_len.test\"]]\n",
    "\n",
    "data, maps = easy_rec.data_generation_utils.preprocess_dataset(**cfg[\"data_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "SZlmqNYmPEi5"
   },
   "outputs": [],
   "source": [
    "datasets = easy_rec.rec_torch.prepare_rec_datasets(data,**cfg[\"data_params\"][\"dataset_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "D3TNmTzuPEi6"
   },
   "outputs": [],
   "source": [
    "cfg[\"data_params\"][\"collator_params\"][\"num_items\"] = np.max(list(maps[\"sid\"].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "O5vbk890943h"
   },
   "outputs": [],
   "source": [
    "collators = easy_rec.rec_torch.prepare_rec_collators(**cfg[\"data_params\"][\"collator_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3vp7Lk7zPEi6"
   },
   "outputs": [],
   "source": [
    "loaders = easy_rec.rec_torch.prepare_rec_data_loaders(datasets, **cfg[\"model\"][\"loader_params\"], collate_fn=collators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_F2mkse943h"
   },
   "source": [
    "### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "UR-JJTEbPEi6"
   },
   "outputs": [],
   "source": [
    "cfg[\"model\"][\"rec_model\"][\"num_items\"] = np.max(list(maps[\"sid\"].values()))\n",
    "cfg[\"model\"][\"rec_model\"][\"num_users\"] = np.max(list(maps[\"uid\"].values()))\n",
    "cfg[\"model\"][\"rec_model\"][\"lookback\"] = cfg[\"data_params\"][\"collator_params\"][\"lookback\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Txcoo55qPEi6",
    "outputId": "4a9ce068-04e0-444e-cc97-42c1bfc1cc6e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "/home/caldia/recsys-svd/rec_svd/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#load the default SASRec module with the specified parameters\n",
    "main_module = easy_rec.rec_torch.create_rec_model(**cfg[\"model\"][\"rec_model\"])\n",
    "#print(main_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bsK2UMwV943i"
   },
   "source": [
    "#### TRAINING PROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "qyx8nphvPEi7",
    "outputId": "1ef794b0-f602-49c8-bf0f-26b44944c565"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment already found: True ----> The experiment id is: zfmgG7mdl83IVwwD\n"
     ]
    }
   ],
   "source": [
    "exp_found, experiment_id = easy_exp.exp.get_set_experiment_id(cfg)\n",
    "print(\"Experiment already found:\", exp_found, \"----> The experiment id is:\", experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Gh6sJ0dAPEi7",
    "outputId": "261337b3-1a4f-415d-e769-e62cd8c9f72c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "trainer_params = easy_torch.preparation.prepare_experiment_id(cfg[\"model\"][\"trainer_params\"], experiment_id)\n",
    "\n",
    "# Prepare callbacks and logger using the prepared trainer_params\n",
    "trainer_params[\"callbacks\"] = easy_torch.preparation.prepare_callbacks(trainer_params)\n",
    "trainer_params[\"logger\"] = easy_torch.preparation.prepare_logger(trainer_params)\n",
    "\n",
    "# Prepare the trainer using the prepared trainer_params\n",
    "trainer = easy_torch.preparation.prepare_trainer(**trainer_params)\n",
    "\n",
    "model_params = cfg[\"model\"].copy()\n",
    "\n",
    "model_params[\"loss\"] = easy_torch.preparation.prepare_loss(cfg[\"model\"][\"loss\"], easy_rec.losses)\n",
    "\n",
    "# Prepare the optimizer using configuration from cfg\n",
    "model_params[\"optimizer\"] = easy_torch.preparation.prepare_optimizer(**cfg[\"model\"][\"optimizer\"])\n",
    "\n",
    "# Prepare the metrics using configuration from cfg\n",
    "model_params[\"metrics\"] = easy_torch.preparation.prepare_metrics(cfg[\"model\"][\"metrics\"], easy_rec.metrics)\n",
    "\n",
    "# Create the model using main_module, loss, and optimizer\n",
    "model = easy_torch.process.create_model(main_module, **model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "En-AS55j943j"
   },
   "source": [
    "### PRUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "yrF1cXup943j",
    "outputId": "8bfebdf3-e6a2-448b-c1f4-4531cb62f459"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_670256/517621337.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(best_model_path, map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaseNN(\n",
       "  (main_module): SASRec(\n",
       "    (item_emb): Embedding(1077, 64, padding_idx=0)\n",
       "    (pos_emb): Embedding(200, 64)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.2, inplace=False)\n",
       "          (dropout2): Dropout(p=0.2, inplace=False)\n",
       "          (activation): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (last_layernorm): LayerNorm((64,), eps=1e-08, elementwise_affine=True)\n",
       "  )\n",
       "  (loss): SequentialBCEWithLogitsLoss()\n",
       "  (metrics): RobustModuleDict(\n",
       "    (module_dict): ModuleDict(\n",
       "      (train____): ModuleList(\n",
       "        (0): ModuleDict(\n",
       "          (Precision): Precision()\n",
       "          (Recall): Recall()\n",
       "          (F1): F1(\n",
       "            (precision): Precision()\n",
       "            (recall): Recall()\n",
       "          )\n",
       "          (MAP): MAP(\n",
       "            (precision_at_k): PrecisionWithRelevance()\n",
       "          )\n",
       "          (NDCG): NDCG()\n",
       "          (MRR): MRR()\n",
       "        )\n",
       "      )\n",
       "      (val____): ModuleList(\n",
       "        (0-1): 2 x ModuleDict(\n",
       "          (Precision): Precision()\n",
       "          (Recall): Recall()\n",
       "          (F1): F1(\n",
       "            (precision): Precision()\n",
       "            (recall): Recall()\n",
       "          )\n",
       "          (MAP): MAP(\n",
       "            (precision_at_k): PrecisionWithRelevance()\n",
       "          )\n",
       "          (NDCG): NDCG()\n",
       "          (MRR): MRR()\n",
       "        )\n",
       "      )\n",
       "      (test____): ModuleList(\n",
       "        (0): ModuleDict(\n",
       "          (Precision): Precision()\n",
       "          (Recall): Recall()\n",
       "          (F1): F1(\n",
       "            (precision): Precision()\n",
       "            (recall): Recall()\n",
       "          )\n",
       "          (MAP): MAP(\n",
       "            (precision_at_k): PrecisionWithRelevance()\n",
       "          )\n",
       "          (NDCG): NDCG()\n",
       "          (MRR): MRR()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load checkpoint of experiment with emb_size = 64\n",
    "\n",
    "models_path = os.path.join(out_folder, \"models/amz_beauty\")\n",
    "best_model_path = os.path.join(models_path, experiment_id+'/best.ckpt')\n",
    "\n",
    "checkpoint = torch.load(best_model_path, map_location=torch.device('cpu'))\n",
    "state_dict = checkpoint['state_dict']\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "#print(main_module.item_emb.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7YgTpSwk943k",
    "outputId": "256a3dc9-85db-459c-b3bd-af1898bb1cfc"
   },
   "outputs": [],
   "source": [
    "#print(\"Before pruning there are \",main_module.item_emb.weight.data[main_module.item_emb.weight.data == 0].shape[0], \" zero elements.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yrQClzNp943k",
    "outputId": "d7029784-db6a-4816-9c81-7992b3f1f067"
   },
   "outputs": [],
   "source": [
    "pruning = \"no\"\n",
    "\n",
    "pruning_percentage = 50\n",
    "\n",
    "if pruning == \"weight_pruning\":\n",
    "    weight_pruning(main_module.item_emb, pruning_percentage)\n",
    "\n",
    "elif pruning == \"neuron_pruning\":\n",
    "    pruned_neurons = neuron_pruning(main_module.item_emb, pruning_percentage)\n",
    "    print(sorted(pruned_neurons))\n",
    "\n",
    "elif pruning == \"lazy_neuron_pruning\":\n",
    "    lazy_pruned_neurons = lazy_neuron_pruning(main_module.item_emb, pruning_percentage)\n",
    "    print(\"Lazy pruned neurons: \", lazy_pruned_neurons)\n",
    "\n",
    "else:\n",
    "    print(\"Incorrect pruning type!\")\n",
    "\n",
    "#print(\"After pruning there are \",main_module.item_emb.weight.data[main_module.item_emb.weight.data == 0].shape[0], \" zero elements.\")\n",
    "#print(main_module.item_emb.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1boUS8GM943k"
   },
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "660caa91a5ae4de0ac6959041186a914"
     ]
    },
    "id": "g3ACWrhHPEi8",
    "outputId": "d28eb458-ccbb-44e2-e9e8-30a9c80243db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f35f79f43b846178bd864c4f1e66883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_F1_@10        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.003884220030158758    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_F1_@20        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0068124630488455296   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_F1_@5         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.003066218225285411    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_MAP_@10        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0023055432830005884   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_MAP_@20        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.003176265861839056    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_MAP_@5        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0022946104872971773   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_MRR_@10        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.006833869963884354    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_MRR_@20        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.010857326909899712    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_MRR_@5        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0051282052882015705   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_NDCG_@10       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.011499150656163692    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_NDCG_@20       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.026052603498101234    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_NDCG_@5        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.006963436957448721    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test_Precision_@10     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0027472530491650105   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test_Precision_@20     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.004238618537783623    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_Precision_@5     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.002511773956939578    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_Recall_@10      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.02747252769768238    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_Recall_@20      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08477237075567245    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_Recall_@5       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.012558870017528534    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5443797707557678     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_F1_@10       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.003884220030158758   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_F1_@20       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0068124630488455296  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_F1_@5        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.003066218225285411   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_MAP_@10       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0023055432830005884  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_MAP_@20       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.003176265861839056   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_MAP_@5       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0022946104872971773  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_MRR_@10       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.006833869963884354   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_MRR_@20       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.010857326909899712   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_MRR_@5       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0051282052882015705  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_NDCG_@10      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.011499150656163692   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_NDCG_@20      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.026052603498101234   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_NDCG_@5       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.006963436957448721   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test_Precision_@10    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0027472530491650105  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test_Precision_@20    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.004238618537783623   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_Precision_@5    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.002511773956939578   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_Recall_@10     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.02747252769768238   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_Recall_@20     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08477237075567245   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_Recall_@5      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.012558870017528534   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5443797707557678    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "easy_torch.process.test_model(trainer, model, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A79Y5iATPEi8",
    "outputId": "d509656a-e82d-47a1-9eee-8a94336f5367"
   },
   "outputs": [],
   "source": [
    "# Save experiment and print the current configuration\n",
    "#save_experiment_and_print_config(cfg)\n",
    "easy_exp.exp.save_experiment(cfg)\n",
    "\n",
    "# Print completion message\n",
    "print(\"Execution completed.\")\n",
    "print(\"######################################################################\")\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "2nRCG0Q8347G",
    "c81IM9YmWpCp",
    "4vggorg-dp0E",
    "o9gCiPA9dp0H",
    "IqoE-m8ndp0I"
   ],
   "provenance": [
    {
     "file_id": "1wtP3Ea5fb_9Zq8JtczLnv8HMfa3GE6wv",
     "timestamp": 1714501219456
    }
   ]
  },
  "kernelspec": {
   "display_name": "rec_svd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
