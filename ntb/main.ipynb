{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nRCG0Q8347G"
   },
   "source": [
    "# Preparation stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c81IM9YmWpCp"
   },
   "source": [
    "## Connect to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EoEPCwJGdpz_"
   },
   "outputs": [],
   "source": [
    "connect_to_drive = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QgLWUVMAWpCq"
   },
   "outputs": [],
   "source": [
    "#Run command and authorize by popup --> other window\n",
    "if connect_to_drive:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzMilQQcEL-w"
   },
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "w9_OVsonPEi1"
   },
   "outputs": [],
   "source": [
    "if connect_to_drive:\n",
    "    #Install FS code\n",
    "    #!pip install  --upgrade --no-deps --force-reinstall git+https://github.com/federicosiciliano/easy_lightning.git@fedsic\n",
    "    !pip install  --upgrade --no-deps --force-reinstall git+https://github.com/PokeResearchLab/easy_lightning.git\n",
    "\n",
    "    !pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llsyZg59yyiX"
   },
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "U0GsBSD6yz9y"
   },
   "outputs": [],
   "source": [
    "#Put all imports here\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from copy import deepcopy\n",
    "#import pickle\n",
    "import os\n",
    "import sys\n",
    "#import cv2\n",
    "import torch\n",
    "import csv\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import setuptools.dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnSShc_Yy4lr"
   },
   "source": [
    "## Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WRYc5NEeyjQ8"
   },
   "outputs": [],
   "source": [
    "#every path should start from the project folder:\n",
    "project_folder = \"../\"\n",
    "if connect_to_drive:\n",
    "    project_folder = \"/content/gdrive/Shareddrives/<SharedDriveName>\" #Name of SharedDrive folder\n",
    "    #project_folder = \"/content/gdrive/MyDrive/<MyDriveName>\" #Name of MyDrive folder\n",
    "\n",
    "#Config folder should contain hyperparameters configurations\n",
    "cfg_folder = os.path.join(project_folder,\"cfg\")\n",
    "\n",
    "#Data folder should contain raw and preprocessed data\n",
    "data_folder = os.path.join(project_folder,\"data\")\n",
    "raw_data_folder = os.path.join(data_folder,\"raw\")\n",
    "processed_data_folder = os.path.join(data_folder,\"processed\")\n",
    "\n",
    "#Source folder should contain all the (essential) source code\n",
    "source_folder = os.path.join(project_folder,\"src\")\n",
    "\n",
    "#The out folder should contain all outputs: models, results, plots, etc.\n",
    "out_folder = os.path.join(project_folder,\"out\")\n",
    "img_folder = os.path.join(out_folder,\"img\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4fhGkp14CSb"
   },
   "source": [
    "## Import own code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To import from src:\n",
    "\n",
    "#attach the source folder to the start of sys.path\n",
    "sys.path.insert(0, project_folder)\n",
    "\n",
    "#import from src directory\n",
    "from src.module import *\n",
    "\n",
    "import easy_exp, easy_rec, easy_torch #easy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIslF_wh31z2"
   },
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSozb3hnPEi4"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9gCiPA9dp0H"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "1oW5REUm4GC8"
   },
   "outputs": [],
   "source": [
    "cfg = easy_exp.cfg.load_configuration(\"config_rec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---> for _ in cfg.sweep(\"data_params.name\"):\n",
    "#---> for _ in cfg.sweep(\"model.rec_model.emb_size\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "De8GmtGYPEi4"
   },
   "outputs": [],
   "source": [
    "data_params = deepcopy(cfg[\"data_params\"])\n",
    "data_params[\"data_folder\"] = raw_data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mmEpjTWdPEi5",
    "outputId": "0f937531-5fda-4c34-ab77-cd324d262972"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings data already exists. Skip pre-processing\n",
      "Filtering by minimum number of users per item: 5\n",
      "Filtering by minimum number of items per user: 5\n",
      "Densifying index\n",
      "Splitting: leave_n_out\n"
     ]
    }
   ],
   "source": [
    "data, maps = easy_rec.data_generation_utils.preprocess_dataset(**data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Save user and item mappings\n",
    "# with open(os.path.join(processed_data_folder,\"user_map.csv\"), \"w\") as f_user:\n",
    "#     w = csv.writer(f_user)\n",
    "#     w.writerows(maps['uid'].items())\n",
    "\n",
    "# with open(os.path.join(processed_data_folder,\"item_map.csv\"), \"w\") as f_item:\n",
    "#     w = csv.writer(f_item)\n",
    "#     w.writerows(maps['sid'].items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "SZlmqNYmPEi5"
   },
   "outputs": [],
   "source": [
    "datasets = easy_rec.rec_torch.prepare_rec_datasets(data,**data_params[\"dataset_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "D3TNmTzuPEi6"
   },
   "outputs": [],
   "source": [
    "collator_params = deepcopy(data_params[\"collator_params\"])\n",
    "collator_params[\"num_items\"] = np.max(list(maps[\"sid\"].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "collators = easy_rec.rec_torch.prepare_rec_collators(**collator_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "3vp7Lk7zPEi6"
   },
   "outputs": [],
   "source": [
    "loader_params = deepcopy(cfg[\"model\"][\"loader_params\"])\n",
    "loaders = easy_rec.rec_torch.prepare_rec_data_loaders(datasets, **loader_params, collate_fn=collators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "UR-JJTEbPEi6"
   },
   "outputs": [],
   "source": [
    "rec_model_params = deepcopy(cfg[\"model\"][\"rec_model\"])\n",
    "rec_model_params[\"num_items\"] = np.max(list(maps[\"sid\"].values()))\n",
    "rec_model_params[\"num_users\"] = np.max(list(maps[\"uid\"].values()))\n",
    "rec_model_params[\"lookback\"] = collator_params[\"lookback\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Txcoo55qPEi6",
    "outputId": "4a9ce068-04e0-444e-cc97-42c1bfc1cc6e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "#load the default SASRec module with the specified parameters\n",
    "main_module = easy_rec.rec_torch.create_rec_model(**rec_model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg[\"model\"].get(\"svd\",False):\n",
    "    svd_cfg = get_svd_cfg(cfg)\n",
    "    svd_exp_found, svd_experiment_id = easy_exp.exp.get_set_experiment_id(svd_cfg)\n",
    "    if not svd_exp_found: raise Exception(\"SVD experiment not found\")\n",
    "    svd_results = load_svd_results(processed_data_folder, svd_cfg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = rec_model_params[\"num_users\"]\n",
    "num_items = cfg[\"model\"][\"rec_model\"][\"num_items\"]\n",
    "\n",
    "utility_matrix = create_utility_matrix_from_dataset(datasets['train'], num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, v_t = np.linalg.svd(utility_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from npmf import npmf\n",
    "from npmf.npmf import models\n",
    "\n",
    "\n",
    "# hyperparameters\n",
    "k = 64\n",
    "init_lr = 0.1\n",
    "decay_rate = 1/1.2\n",
    "lambda_u = 0.1\n",
    "lambda_i = 0.1\n",
    "nanvalue = 0\n",
    "max_iter=100\n",
    "\n",
    "# factorize data matrix\n",
    "W, Z, user_biases, item_biases, loss, err_train, pred_fn = \\\n",
    "    npmf.models.sgd(utility_matrix, num_features=k, nanvalue=nanvalue, lr0=init_lr, batch_size=128,\n",
    "                    decay_fn=lambda lr, step: npmf.learning_rate_decay.inverse_time_decay(lr, step, decay_rate, max_iter),\n",
    "                    lambda_user=lambda_u, lambda_item=lambda_i, max_iter=max_iter)\n",
    "M_hat = pred_fn(W, Z, user_biases, item_biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the item embedding layer with SVD right matrix (if freeze_emb=True the matrix weights will remain fixed)\n",
    "useSVD = cfg[\"model\"][\"useSVD\"]\n",
    "\n",
    "if useSVD:\n",
    "    freeze_emb = cfg[\"model\"].get(\"freeze_emb\",False)\n",
    "    cfg[\"model.freeze_emb\"] = freeze_emb\n",
    "    use_diag = cfg[\"model\"].get(\"use_diag\",False)\n",
    "    cfg[\"model.use_diag\"] = use_diag\n",
    "\n",
    "    num_users = cfg[\"model\"][\"rec_model\"][\"num_users\"]\n",
    "    num_items = cfg[\"model\"][\"rec_model\"][\"num_items\"]\n",
    "    emb_size = cfg[\"model\"][\"rec_model\"][\"emb_size\"]\n",
    "    svd_cutoff = cfg[\"model\"].get(\"svd_cutoff\",1000000)\n",
    "    \n",
    "    utility_matrix = create_utility_matrix_from_dataset(datasets['train'], num_users, num_items)\n",
    "\n",
    "     # new (imputation)\n",
    "    imputation = cfg[\"model\"][\"mean_imputation\"]\n",
    "    centered_utility_matrix = mean_imputation(utility_matrix, imputation)\n",
    "    embedding_matrix = create_embedding_matrix(centered_utility_matrix, emb_size, use_diag)\n",
    "\n",
    "    #embedding_matrix = create_embedding_matrix(utility_matrix, emb_size, use_diag)\n",
    "\n",
    "    new_emb_matrix = torch.tensor(embedding_matrix, dtype=torch.float32)\n",
    "\n",
    "    #initialize the item embedding matrix with the new embedding matrix \n",
    "    if svd_cutoff is not None and svd_cutoff < emb_size:\n",
    "        main_module.item_emb.weight.data[:,:svd_cutoff] = new_emb_matrix[:,:svd_cutoff]\n",
    "    else:\n",
    "        cfg[\"model\"].pop(\"svd_cutoff\",None) #remove the svd_cutoff parameter if not used\n",
    "        #to keep consistent with previous configs\n",
    "        main_module.item_emb.weight.data = new_emb_matrix\n",
    "\n",
    "    if freeze_emb:\n",
    "        for param in main_module.item_emb.parameters():\n",
    "            param.requires_grad = False\n",
    "else:\n",
    "    cfg[\"model\"].pop(\"freeze_emb\",None) #remove the freeze_emb parameter if not used\n",
    "    cfg[\"model\"].pop(\"use_diag\",None) #remove the use_diag parameter if not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qyx8nphvPEi7",
    "outputId": "1ef794b0-f602-49c8-bf0f-26b44944c565"
   },
   "outputs": [],
   "source": [
    "exp_found, experiment_id = easy_exp.exp.get_set_experiment_id(cfg)\n",
    "print(\"Experiment already found:\", exp_found, \"----> The experiment id is:\", experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kqzpgKcZPEi7"
   },
   "outputs": [],
   "source": [
    "#if exp_found: exit() #TODO: make the notebook/script stop here if the experiment is already found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gh6sJ0dAPEi7",
    "outputId": "261337b3-1a4f-415d-e769-e62cd8c9f72c"
   },
   "outputs": [],
   "source": [
    "trainer_params = easy_torch.preparation.prepare_experiment_id(cfg[\"model\"][\"trainer_params\"], experiment_id)\n",
    "\n",
    "# Prepare callbacks and logger using the prepared trainer_params\n",
    "trainer_params[\"callbacks\"] = easy_torch.preparation.prepare_callbacks(trainer_params)\n",
    "trainer_params[\"logger\"] = easy_torch.preparation.prepare_logger(trainer_params)\n",
    "\n",
    "# Prepare the trainer using the prepared trainer_params\n",
    "trainer = easy_torch.preparation.prepare_trainer(**trainer_params)\n",
    "\n",
    "model_params = deepcopy(cfg[\"model\"])\n",
    "\n",
    "model_params[\"loss\"] = easy_torch.preparation.prepare_loss(cfg[\"model\"][\"loss\"], easy_rec.losses)\n",
    "\n",
    "# Prepare the optimizer using configuration from cfg\n",
    "model_params[\"optimizer\"] = easy_torch.preparation.prepare_optimizer(**cfg[\"model\"][\"optimizer\"])\n",
    "\n",
    "# Prepare the metrics using configuration from cfg\n",
    "model_params[\"metrics\"] = easy_torch.preparation.prepare_metrics(cfg[\"model\"][\"metrics\"], easy_rec.metrics)\n",
    "\n",
    "# Create the model using main_module, loss, and optimizer\n",
    "model = easy_torch.process.create_model(main_module, **model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZWI94Zv5PEi7"
   },
   "outputs": [],
   "source": [
    "# Prepare the emission tracker using configuration from cfg\n",
    "tracker = easy_torch.preparation.prepare_emission_tracker(**cfg[\"model\"][\"emission_tracker\"], experiment_id=experiment_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jttfzSb5Oezv"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "referenced_widgets": [
      "693bcd1c27f741879227e081b8b2a2bc",
      "10021952d41e4ae7b6d25d230871220a",
      "883e3d26e1f046278cdaa4806044be3c"
     ]
    },
    "id": "SNGT89Tbdp0K",
    "outputId": "c5dd867a-b9f8-4a37-c8ec-35b4d3e05ced"
   },
   "outputs": [],
   "source": [
    "# Train the model using the prepared trainer, model, and data loaders\n",
    "easy_torch.process.train_model(trainer, model, loaders, tracker=tracker, val_key=[\"val\",\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "660caa91a5ae4de0ac6959041186a914"
     ]
    },
    "id": "g3ACWrhHPEi8",
    "outputId": "d28eb458-ccbb-44e2-e9e8-30a9c80243db"
   },
   "outputs": [],
   "source": [
    "easy_torch.process.test_model(trainer, model, loaders, tracker=tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A79Y5iATPEi8",
    "outputId": "d509656a-e82d-47a1-9eee-8a94336f5367"
   },
   "outputs": [],
   "source": [
    "# Save experiment and print the current configuration\n",
    "#save_experiment_and_print_config(cfg)\n",
    "easy_exp.exp.save_experiment(cfg)\n",
    "\n",
    "# Print completion message\n",
    "print(\"Execution completed.\")\n",
    "print(\"######################################################################\")\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "2nRCG0Q8347G",
    "c81IM9YmWpCp",
    "4vggorg-dp0E",
    "o9gCiPA9dp0H",
    "IqoE-m8ndp0I"
   ],
   "provenance": [
    {
     "file_id": "1wtP3Ea5fb_9Zq8JtczLnv8HMfa3GE6wv",
     "timestamp": 1714501219456
    }
   ]
  },
  "kernelspec": {
   "display_name": "rec_svd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
